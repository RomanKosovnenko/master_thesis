\chapter{Evaluation and Analysis}

\section{Evaluation}
\subsection{Benchmark set}
Benchmark set consist of 36 problems with different sizes.

This set was tested with several versions of genetic solver
\begin{itemize}
	\item basic
	\item with new parameters
	\item without duplicates
\end{itemize}
all parameters were unoptimized.

What I need more:
\begin{itemize}
	\item number of runs to get valid results, or no solutions
	\item Using best configuration test 36 problems (for static at least)
\end{itemize}


\subsection{Benchmark results}
\subsection{Compare with random solver}

\section{Analysis}
Why it works very bad!
\begin{itemize}
	\item Good parameter engineering 
	\item Self-adaptive software is not the best thing to optimize!
	\item GA is not the best idea for this kind of problem
\end{itemize}

Plots for analysis:
\begin{itemize}
	\item Search space view
	\item correlation
	\item distribution of two parameters
	\item list for combinations of 3-15
	\item Barplots that shows that solver could find optimal results or near optimal 
	combined chart of validity and objective to parameter
	
\end{itemize}